# 选题背景与意义

​	随着人工智能领域的发展，数据孤岛的问题越来越明显，在用户隐私愈受保护的今天，不同的隐私数据保护法被颁布，如何在确保隐私数据安全的同时更促进企业间合作，从多方数据中得到一个更好更精确的学习模型。在多方共同学习的同时，需要确保隐私的安全，一方面，客户机在每个训练时段发送的模型更新可能会泄漏客户机私有数据的信息；另一方面，服务器学习到的模型可能会受到恶意客户端的攻击。这些可以通过例如差异隐私和数据加密的方案提高分布式学习系统的隐私安全性，而这些概念被总结为不同的联邦学习方法，像FedAvg、VFL等算法就是这样的研究。

​	自从2016年 Google 提出联邦学习这一概念以来，联邦学习也在不断发展，从最初的仅有横向联邦学习到联邦学习分类为横向联邦学习、纵向联邦学习和联邦迁移学习。为了在项目中使用到联邦学习算法，业界也需要一个像TensorFlow和Pytorch一样的学习框架，像Google在自己的TensorFlow框架中就集成了联邦学习方法成为TFF，而TFF由于太过于底层，对于研究不同算法和算法的改进研究更为方便，但许多底层的参数都需要开发人员自己去适配，不易于使用，因此许多研究机构和企业也纷纷开发出自己的联邦学习框架，例如京东的9NFL、微众的FATE、字节的FedLearner、百度的PaddleFL等。本毕设将基于USC的FedML框架进行研究，学习不同联邦学习算法在FedML框架中的应用，对FedML框架进行适配性开发，使其能够最后接入已开发的联邦学习中心平台。

# 研究基本内容和拟解决的主要问题

## 研究的基本内容

本次毕设基于实验室与中国移动合作的项目，需要开发一个联邦学习聚合平台，能够使多个业务方在保证数据隐私的前提下合作对同一个模型进行联邦学习的训练。在本次毕设中希望能开发一个原型项目，让实验室和中国电信之后能基于此进行开发或参考。

## 研究目标和效果

通过对已有的FedML框架进一步开发，使得开发后的项目能够在业务机器进行简单部署，机器间通过通信交换非隐私数据共同训练模型。并且能够提供API接入联邦平台中心服务器，方便实时监控各机器上的模型训练情况。

## 拟解决的主要问题

### FedML框架优化

FedML基于学术研究的目的，作为开源项目文档也很丰富，对于不同的联邦学习算法很包容，也在不断更新框架以适配NLP、CV等的联邦学习方法，相比于TFF(TensorFlow Federated)等的联邦学习框架，FedML有更进一步的封装，通过简单配置好训练集、测试集、训练的模型和联邦学习算法就可以直接进行训练。本毕设需要开发后台服务直接通过调用服务的方式在本地进行模型训练，并且要使训练过程能够实现监控的可视化，仍需要在原框架的基础上进行服务开发，通过集成API的形式，方便服务调用方使用该联邦学习的服务。

首先需要对框架的源码进行熟悉，明白各个函数的调用，编写新的业务层，调用这些函数从而实现不同的功能，并通过控制层的接口调用业务层的服务，这样一个大致的思路对FedML框架进行优化，以适配该毕设的项目研究。

### 联邦学习方法的改进

尽管在FedML框架中已经集成了FedAvg、FedOpt等不同的联邦学习算法，在这些算法上阅读相关论文，理解算法。并基于已有的联邦学习算法，能够提出创新点，进行算法上的改进。在不同的模型和不同的训练集上对改进算法进行实验研究，能实现联邦学习性能上的一些优化。

### 各分布式机器上通信传输优化

在原FedML项目中，各分布式机器间的通信方式采用的是MPI，本项目中会拟实现其他通信方式，以方便统一适配已开发的联邦学习中心平台项目。

# 研究方法及措施

（1）查阅并阅读相关论文，对所需要使用的联邦学习方法和机器学习模型有一定的了解。

（2）研究调试FedML框架源码，通过对框架的单机计算、分布式计算的使用，学习框架的运行原理和适配过程。

（3）由于联邦学习也在不断发展，在完成毕设过程中可以研究联邦学习的最新动态，并对现有联邦学习算法进行创新点改进提出更好的解决方案。

# 研究工作的步骤与进度

2021年12月16日-2021年12月30日：了解课题目标及内容，查找相关资料并学习。

2022年1月1日-2022年1月14日：完成FedML联邦学习基本模型的实验。

2022年1月15日-2022年3月30日：分析引擎的训练模块与预测推理模块，完成分析报告。

2022年4月1日-2022年4月14日：设计与实现联邦学习横向图像分类算法。

2022年4月15日-2022年4月30日：设计实现适配FedML引擎的模型管理微服务模块。

2022年5月1日-2022年5月30日：完成毕设论文与答辩。

# 主要参考文献

[1] H. Brendan McMahan and Eider Moore and Daniel Ramage and Seth Hampson and Blaise Agüera y Arcas McMahan. Communication-Efficient Learning of Deep Networks from Decentralized Data. arXiv:1602.05629, 2016.
[2] Chaoyang He, Songze Li, Jinhyun So, Xiao Zeng, Mi Zhang, Hongyi Wang, Xiaoyang Wang, Praneeth Vepakomma, Abhishek Singh, Hang Qiu, Xinghua Zhu, Jianzong Wang, Li Shen, Peilin Zhao, Yan Kang, Yang Liu, Ramesh Raskar, Qiang Yang, Murali Annavaram, Salman Avestimehr. FedML: A Research Library and Benchmark for Federated Machine Learning.  arXiv:2007.13518, 2020.
[3] Milad Khademi Nori, Sangseok Yun, Il-Min Kim. Fast Federated Learning by Balancing Communication Trade-Offs.  arXiv:2105.11028, 2021.
[4] Hongxu Yin, Arun Mallya, Arash Vahdat, Jose M. Alvarez, Jan Kautz, Pavlo Molchanov. See through Gradients: Image Batch Recovery via GradInversion.  arXiv:2104.07586, 2021.
[5] Alberto Blanco-Justicia, Josep Domingo-Ferrer, Sergio Martínez, David Sánchez, Adrian Flanagan, Kuan Eeik Tan. Achieving Security and Privacy in Federated Learning Systems: Survey, Research Challenges and Future Directions. arXiv:2012.06810, 2020.
[6] HizT. Federal Learning中的隐私问题. Publically available at https://www.jianshu.com/p/af2866fa068a.
[7] Story. 机器学习隐私保护综述. Publically available at https://zhuanlan.zhihu.com/p/246421757.
[8] 成招荣. 2021年中国隐私计算行业市场现状及发展前景. Publically available at https://www.qianzhan.com/analyst/detail/220/211013-81160498.html.
[9] Jomaron. 机器学习与隐私保护. Publically available at https://blog.csdn.net/qiu1440528444/article/details/97375153.
[10] 周蕾. 微众银行首席AI官杨强：万字图文详谈联邦学习最前沿. Publically available at https://www.leiphone.com/category/DataSecurity%20/QwiDxfL26LI3ncUn.html
